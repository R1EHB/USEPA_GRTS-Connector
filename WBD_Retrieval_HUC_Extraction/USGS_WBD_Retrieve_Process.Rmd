---
title: HUC-it's Grab and Go with WBD
author: beck.erik@epa.gov
date: May 8, 2025
---

# Overview #

# Disclaimer #
* Not an official EPA product

# Notes #
GPKG file format handling is partially implemented here, but commented out.
Uncomment if needed. GPKG files are large (8-10 gigabytes in this case), 
so that functionality here is disabled to save time and bandwidth.

# Setup #

## Libraries ##

```{r Intro}
## Get Current Watershed Boundary Dataset and related files to tease
## out HUC codes from the USA and surrounding boundary areas (Canada,
## Mexico) into a set of spreadsheets
```

```{r LoadLibs}
## Load needed libraries
## st_layers is part of SF package


if (!require (sf)) {
   install.packages("sf", repos="https://cloud.r-project.org")
   }

if (!require (curl)) {
   install.packages("curl", repos="https://cloud.r-project.org")
   }

if (!require (tibble)) {
   install.packages("tibblecurl", repos="https://cloud.r-project.org")
   }

if (!require (gpkg)) {
   install.packages("gpkg", repos="https://cloud.r-project.org")
}

if (!require (here)) {
   install.packages("here", repos="https://cloud.r-project.org")
}
   
library (sf)
library (curl)
library (tibble)
library (gpkg)
library (here)
```
## Working Directories ##

### Existing Directories ###

Using Linux/Unix path notation, the overall project base directory is:

* LOCAL_BASE_DIR='I_Ran_Git_Clone_Here}/USEPA_GRTS-Connector/'

The startup directory for Rstudio, where this file lives is, relative to BASE_DIR:
* $LOCAL_BASE_DIR/WBD_Retrieval_HUC_Extraction/

The data files will be stored and used from subdirectories off of:
* $LOCAL_BASE_DIR/Data_IO/

```{r setup}
# Make and Set Working directory

# Relative to Startup Directory

# Save Current Directory

## STARTUP_DIR <- getwd()

STARTUP_DIR <- here()

## Paths Relative to STARTUP_DIR



knitr::opts_knit$set(root.dir = STARTUP_DIR)

setwd("..")

LOCAL_BASE_DIR <- getwd()
DATA_ROOT_DIR <- paste(LOCAL_BASE_DIR,'/DATA_IO/', sep="")
WBD_DATA_DIR <- paste(DATA_ROOT_DIR,'WBD_DATA_DIR/', sep="")
HUC_REVISION_DIR <- paste (DATA_ROOT_DIR,'2020_HUC_Revision-Concordance/', sep="")

HUC_OUTPUT_DIR <- paste (DATA_ROOT_DIR,'HUC-Data-Lists/', sep="")

print (WBD_DATA_DIR)
print (HUC_REVISION_DIR)
print (HUC_OUTPUT_DIR)

```




### Create New Directories ###



``` {r create-output-dir}
dir.create (WBD_DATA_DIR)
dir.create(HUC_OUTPUT_DIR)

```

# Pull in the Data from USGS #

```{r retrieve-data-USGS_AWS}
setwd(WBD_DATA_DIR)

AWS_base_URL <- "https://prd-tnm.s3.amazonaws.com/StagedProducts/Hydrography/WBD/National"

g_types = c("/GDB/","/GPKG/")


## GDB file is about 2.5 Gb
GDB_fnames <- c("WBD_National_GDB.jpg",
		"WBD_National_GDB.xml","WBD_National_GDB.zip")

## this is really large (2x or 3x size of GDB) so commented out. Uncomment if needed
## GPKG_fnames <- c("WBD_National_GPKG.jpg",
	##	 "WBD_National_GPKG.xml","WBD_National_GPKG.zip")


str (AWS_base_URL)
## str (GPKG_fnames)
str (GDB_fnames)
str (g_types)
```

```{r expand-files}
setwd(WBD_DATA_DIR)
get_file <- function(base_dir_, g_type_,f_name_) {
  compose_filename <- paste(base_dir_,g_type_,f_name_,sep = "")
  print(compose_filename)
  print(f_name_)

  if (!file.exists(f_name_)) {
    download.file(compose_filename, destfile=f_name_, method = "curl")
    # Check to see if it is a zip file; if so, unzip it
    is_zip <- grepl(".zip", f_name_,ignore.case=TRUE)

    if (is_zip) {
        command_string = paste ("unzip -u",f_name_, sep = " ")
	system(command_string)
    }	
  }
}

  
for (a in  1:3) {
 
  get_file(AWS_base_URL,g_types[1],GDB_fnames[a])
    }

## for (b in 1:3) {
  ## get_file(AWS_base_URL,g_types[2],GPKG_fnames[b])
    ## }
  



gdb <- path.expand("../Data_IO/WBD_Data_DIR/WBD_National_GDB.gdb")

print (gdb)
```

```{r create-huc-lists}
## Note: HUC14 and HUC16 are experimental for USGS and not widely deployed

## Cluster the layer read operations by HUC level together

HUC2 <- st_read(dsn=gdb,layer="WBDHU2")
HUC4 <- st_read(dsn=gdb,layer="WBDHU4")
HUC6 <- st_read(dsn=gdb,layer="WBDHU6")
HUC8 <- st_read(dsn=gdb,layer="WBDHU8")
HUC10 <- st_read(dsn=gdb,layer="WBDHU10")
HUC12 <- st_read(dsn=gdb,layer="WBDHU12")
HUC14 <- st_read(dsn=gdb,layer="WBDHU14")
HUC16 <- st_read(dsn=gdb,layer="WBDHU16")
```




```{r data-drop}
## Cluster Write Operations together

## NOTE:: For some pacific island territories, the State is either coded as NA or ''. April 2025

## Set non-geometric variables to drop and drop geometry

keepsHUC2   <- c("huc2","states","name","areasqkm", "areaacres")
HUC2DF_SF   <- subset(HUC2, select = keepsHUC2)
HUC2DF      <- st_drop_geometry(HUC2DF_SF)

keepsHUC4   <- c("huc4","states","name","areasqkm", "areaacres")
HUC4DF_SF   <- subset(HUC4, select = keepsHUC4)
HUC4DF      <- st_drop_geometry(HUC4DF_SF)

keepsHUC6  <- c("huc6","states","name","areasqkm", "areaacres")
HUC6DF_SF   <- subset(HUC6, select = keepsHUC6)
HUC6DF <- st_drop_geometry(HUC6DF_SF)

keepsHUC8  <- c("huc8","states","name","areasqkm", "areaacres")
HUC8DF_SF   <- subset(HUC8, select = keepsHUC8)
HUC8DF <- st_drop_geometry(HUC8DF_SF)

keepsHUC10 <- c("huc10","states","name","areasqkm", "areaacres")
HUC10DF_SF  <- subset(HUC10, select = keepsHUC10)
HUC10DF <- st_drop_geometry(HUC10DF_SF)

keepsHUC12 <- c("huc12","states","name","areasqkm", "areaacres")
HUC12DF_SF  <- subset(HUC12, select = keepsHUC12)
HUC12DF <- st_drop_geometry(HUC12DF_SF)

keepsHUC14 <- c("huc14","states","name","areasqkm", "areaacres")
HUC14DF_SF  <- subset(HUC14, select = keepsHUC14)
HUC14DF <- st_drop_geometry(HUC14DF_SF)

keepsHUC16 <- c("huc16","states","name","areasqkm", "areaacres")
HUC16DF_SF  <- subset(HUC16, select = keepsHUC16)
HUC16DF <- st_drop_geometry(HUC16DF_SF)
```


# Old HUC Code Patches #
* Add here patching code for old HUC codes that are being phased out
* Lake Champlain basin prime example
* Currently available info for HUC10 and HUC12
* Just use HUC12 for now, as that is the main use case

## Column names and types in patch file ##


* OBJECTID_2019 (numeric/integer)
* OBJECTID_2015 (numeric/integer)
* TNMID_2019 (text/char)
* TNMID_2015 (text/char)
* AREAACRES_2019 (numeric/float)
* AreaAcres_2015 (numeric/float)
* AREASQKM_2019 (numeric/float)
* AreaSqKm_2015 (numeric/float)
* STATES_2019 (text/char)
* States_2015 (text/char)
* HUC12_2019 (text/char with leading zero)
* HUC12_2015 (text/char with leading zero)
* NAME_2019 (text/char)
* Name_2015 (text/char)
* HUTYPE_2019 (text/char)
* HUType_2015 (text/char)
* HUMOD_2019 (text/char)
* HUMod_2015 (text/char)
* TOHUC_2019 (text/char: need to add leading 0)
* ToHUC_2015 (text/char: need to add leading 0)
* NONCONTRIBUTINGAREAACRES_2019 (numeric/float)
* NonContributingAcres_2015 (numeric/float)
* NONCONTRIBUTINGAREASQKM_2019 (numeric/float)
* NonContributingSqKm_2015 (numeric/float)

```{r huc-patch}

## HUC Area 04 Concordance

huc12_fix <- read.csv("../2020_HUC_Revision-Concordance/WBDHU12_Names_Region04-VT_NY_CN-EPAr1-v1.csv",
	  colClasses = c(rep("numeric",2),rep("character",2),rep("numeric",4),
	  	     rep("character",12),rep("numeric",4)))

head (huc12_fix)

keepsHUC12_fix <-c("AreaAcres_2015", "AreaSqKm_2015",
                   "States_2015", "HUC12_2015","Name_2015" )


huc12_patch  <- subset(huc12_fix, select = keepsHUC12_fix)

newNames <-c ("areasqkm","areaacres","states","huc12","name")
colnames(huc12_patch) <- newNames
HUC12DF <- rbind(HUC12DF,huc12_patch)

```


```{r data-write}
## Write CSV Location

## change back to starting directory
setwd(startup_dir)

## Then change to subdir off starting dir

setwd("./HUC-Data-Lists/")

# Write CSV Files
write.csv (HUC2DF, "National_HUC2List.csv")
write.csv (HUC4DF, "National_HUC4List.csv")
write.csv (HUC6DF, "National_HUC6List.csv")
write.csv (HUC8DF, "National_HUC8List.csv")
write.csv (HUC10DF, "National_HUC10List.csv")
write.csv (HUC12DF, "National_HUC12List.csv")
write.csv (HUC14DF, "National_HUC14List.csv")
write.csv (HUC16DF, "National_HUC16List.csv")
```

# End #
q()










